{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef954652",
   "metadata": {},
   "source": [
    "# Ajuste del Pronóstico de Lluvia del WRF 1.5\n",
    "\n",
    "### Nota:\n",
    "Recuerde ajustar los links de las carpetas, directorios y url's que se encuentran a lo largo del código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e97a9",
   "metadata": {},
   "source": [
    "## Cargar Librerias\n",
    "* Se cargan las librerías esenciales para la manipulación de datos, visualización, cálculos numéricos, manejo de fechas, interacción con la web y operaciones del sistema operativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e1e91713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob # Para buscar archivos en un directorio.\n",
    "import pandas as pd # Para manipulación de datos.\n",
    "import numpy as np # Para cálculos numéricos.\n",
    "from datetime import datetime, date, timedelta # Para fechas y horas.\n",
    "import requests # Para realizar solicitudes HTTP.\n",
    "import urllib.request # Para trabajar con URLs.\n",
    "import io # Para manejar entradas/salidas.\n",
    "import os # Para interactuar con el sistema operativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d9080",
   "metadata": {},
   "source": [
    "## Configuración de Almacenamiento y Fechas para Datos de Lluvia\n",
    "* Se proporciona las de rutas de carpetas ( `carpeta_modelo`, `carpeta_observado`) que se utilizarán para almacenar los datos del modelo y los datos observados de lluvia, respectivamente. Además, se establecen fechas de inicio (`fecha_inicio`) y fin (`fecha_fin`) para cargar archivos de lluvia en un rango específico de días.\n",
    "\n",
    "* El diccionario `meses_espanol` asocia números de meses con sus nombres en español. Además, se definen enlaces base (`enlace_base_mod` y `enlace_base_obs`) que señalan a los servidores donde se encuentran los datos de lluvia pronosticada y observada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "9d4dd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta donde se almacenará los datos procesados\n",
    "carpeta = r\"C:/Users/arias/OneDrive/Documentos/UCR/TFG/Ajuste_Datos/Lluvia/Datos\"\n",
    "\n",
    "# Definición de la ruta de la carpeta donde se almacenarán los datos.\n",
    "carpeta_modelo = f\"{carpeta}/Modelo\"\n",
    "carpeta_observado = f\"{carpeta}/Observado\"\n",
    "\n",
    "#Asignar rango de fechas para cargar archivos de lluvia\n",
    "fecha_inicio = datetime.now().date() - timedelta(days=4)\n",
    "fecha_fin = datetime.now().date() - timedelta(days=1)\n",
    "\n",
    "# Diccionario que asocia números de meses con sus nombres en español\n",
    "meses_espanol = {\n",
    "    1: \"enero\", 2: \"febrero\", 3: \"marzo\", 4: \"abril\", 5: \"mayo\", 6: \"junio\", 7: \"julio\",\n",
    "    8: \"agosto\", 9: \"setiembre\", 10: \"octubre\", 11: \"noviembre\", 12: \"diciembre\"\n",
    "}\n",
    "\n",
    "# Enlace base al servidor donde se encuentran los datos de lluvia pronosticada.\n",
    "enlace_base_mod = \"https://wrf1-5.imn.ac.cr/modelo/backup/TESIS/\"\n",
    "\n",
    "# Enlace base al servidor donde se encuentran los datos de lluvia observada.\n",
    "enlace_base_obs = \"http://intra-files.imn.ac.cr/Intranet_graficos/datos5minutos/registro024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "1e9e13e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 12, 3)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fecha_inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "12fb3ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 12, 6)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fecha_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0daafc",
   "metadata": {},
   "source": [
    "## Verificar que los archivos de Lluvia (Observado y Modelo) de los 3 días anteriores existan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09639294",
   "metadata": {},
   "source": [
    "### Función de Carga y Procesamiento de Datos de Lluvia\n",
    "\n",
    "La función `cargar_datos` gestiona la carga y procesamiento de archivos relacionados con la lluvia. En primer lugar, utiliza la información de la fecha proporcionada, desglosándola en componentes como año, mes y día, así como el nombre del mes en español. Luego, construye los enlaces completos para los archivos de lluvia observada y pronosticada, utilizando estos componentes y las direcciones base proporcionadas.\n",
    "\n",
    "La función realiza verificaciones para asegurarse de que los archivos de lluvia observada y pronosticada estén disponibles mediante solicitudes HTTP a los respectivos enlaces. Si ambos archivos están presentes, la función decodifica y lee el archivo CSV de lluvia pronosticada, verificando la presencia de valores negativos o cadenas en los datos. Si se encuentran tales valores problemáticos, se emite un mensaje y el archivo no se carga. En caso contrario, se almacenan los datos observados, los datos pronosticados y la fecha correspondiente en listas específicas.\n",
    "\n",
    "En situaciones donde uno o ambos archivos no están disponibles, la función emite un mensaje indicando archivos faltantes y agrega la fecha a una lista de datos faltantes. Finalmente, la función devuelve las listas actualizadas de datos pronosticados, observados y las fechas de los archivos procesados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1dd3bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar datos y procesar archivos\n",
    "def cargar_datos(fecha, fecha_anterior, COLUMN_NAMES, enlace_base_obs, enlace_base_mod, meses_espanol):\n",
    "    \n",
    "    # Desglosar la fecha en sus componentes: año, mes, día y nombre del mes en español\n",
    "    año, mes, dia, mes_text = fecha.year, fecha.month, fecha.day, meses_espanol[fecha.month]\n",
    "\n",
    "    # Crear el URL completo del archivo de lluvia observada utilizando los componentes de la fecha\n",
    "    url_observado = f\"{enlace_base_obs}/{año}/{mes_text}/{dia}_{mes}_{año}_acum024.txt\"\n",
    "\n",
    "    # Formar el enlace completo para el archivo CSV con la fecha actual y siguiente\n",
    "    url_modelo = f\"{enlace_base_mod}{fecha_anterior.strftime('%Y%m%d')}/{fecha.strftime('%Y%m%d')}.lluvia.csv\"\n",
    "\n",
    "    # Verificar si el archivo de lluvia observada existe antes de descargarlo\n",
    "    response_obs = requests.get(url_observado)\n",
    "    response_mod = requests.get(url_modelo)\n",
    "\n",
    "    if response_obs.status_code == 200 and response_mod.status_code == 200:\n",
    "        # Decodificar y leer los datos del archivo CSV de lluvia pronosticada\n",
    "        mod_data = response_mod.content.decode('utf-8')\n",
    "        df = pd.read_csv(io.StringIO(mod_data), header=None, names=COLUMN_NAMES)\n",
    "\n",
    "        # Verificar la presencia de valores negativos o cadenas en el archivo de lluvia pronosticada\n",
    "        negative_values = (df[COLUMN_NAMES[1:]] < 0).any(axis=0)\n",
    "        str_values = df[COLUMN_NAMES[1:]].applymap(lambda x: isinstance(x, str)).any(axis=0)\n",
    "\n",
    "        # Si hay valores problemáticos, mostrar un mensaje y no cargar el archivo\n",
    "        if (negative_values.any() or str_values.any()):\n",
    "            print(f\"Valores de lluvia pronosticada para {fecha} son negativos o del tipo str. No se carga el archivo.\")\n",
    "            missing_data.append(fecha.strftime(\"%Y%m%d\"))\n",
    "        else:\n",
    "            # Almacenar datos observados, pronosticados y la fecha en listas correspondientes\n",
    "            datos_observados[fecha] = response_obs.text\n",
    "            datos_pronostico.append(df)\n",
    "            file_date.append(fecha.strftime('%Y%m%d'))\n",
    "    else:\n",
    "        # Si falta algún archivo, mostrar un mensaje y agregar la fecha a la lista de datos faltantes\n",
    "        print(f\"Hay archivos faltantes para la fecha {fecha}\")\n",
    "        missing_data.append(fecha.strftime(\"%Y%m%d\"))\n",
    "    \n",
    "    return datos_pronostico, datos_observados, file_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c7084",
   "metadata": {},
   "source": [
    "### Gestión de Datos de Lluvia: Descarga, Procesamiento y Manejo de Fechas\n",
    "\n",
    "Se inicia con la definición de un diccionario `datos_observados` para almacenar el contenido de los archivos de lluvia observada, una lista `datos_pronostico` para almacenar datos de pronóstico, otra lista `file_date` para conservar las fechas de los archivos descargados, y una lista `missing_data` para registrar las fechas de archivos faltantes.\n",
    "\n",
    "Se especifica un conjunto de nombres de columnas `COLUMN_NAMES` para el DataFrame que se creará a partir de los datos de pronóstico. La variable `fecha_anterior` se inicializa con la fecha de inicio, y a continuación, se inicia un bucle que itera sobre el rango de fechas entre `fecha_inicio` y `fecha_fin`.\n",
    "\n",
    "Dentro del bucle, se calcula la fecha del archivo a descargar sumando un día a la fecha anterior. Se construyen las URL completas para los archivos de lluvia observada y pronosticada utilizando los componentes de la fecha. Luego, se realizan solicitudes HTTP para verificar la disponibilidad de ambos archivos.\n",
    "\n",
    "Si algún archivo falta, se muestra un mensaje indicando la ausencia y se agrega la fecha a `missing_data`. También, en este caso, se verifica si es necesario cargar datos de lluvia observada de cuatro días atrás.\n",
    "\n",
    "En caso de que ambos archivos estén disponibles, se decodifica y lee el archivo CSV de lluvia pronosticada. Se verifica la presencia de valores negativos o cadenas en los datos y, si se detectan, se emite un mensaje y se añade la fecha a la lista `missing_data`. Además, si hay menos de dos archivos faltantes, se intenta cargar datos de lluvia observada de cuatro días atrás utilizando la función `cargar_datos`.\n",
    "\n",
    "Finalmente, la fecha anterior se actualiza para la próxima iteración del bucle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d78d6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_observados = {} # Diccionario para almacenar el contenido de los archivos de lluvia observada\n",
    "\n",
    "datos_pronostico = [] # Lista para almacenar los datos de pronóstico\n",
    "\n",
    "file_date = [] # Lista para almacenar las fechas de los archivos descargados\n",
    "\n",
    "missing_data = []# Lista para almacenar las fechas de archivos faltantes\n",
    "\n",
    "COLUMN_NAMES = [\"Estacion\", \"1\", \"2\", \"3\", \"4\"] # Nombres de columnas para el DataFrame\n",
    "\n",
    "fecha_anterior = fecha_inicio # Inicializar la fecha anterior con la fecha de inicio\n",
    "\n",
    "# Iterar sobre el rango de fechas\n",
    "while fecha_anterior < fecha_fin:\n",
    "\n",
    "    fecha = fecha_anterior + timedelta(days=1) # Calcular la fecha del archivo a descargar sumando un día a la fecha anterior\n",
    "\n",
    "    # Desglosar la fecha en sus componentes: año, mes, día y nombre del mes en español\n",
    "    año, mes, dia, mes_text = fecha.year, fecha.month, fecha.day, meses_espanol[fecha.month]\n",
    "\n",
    "    # Crear el URL completo del archivo de lluvia observada utilizando los componentes de la fecha\n",
    "    url_observado = f\"{enlace_base_obs}/{año}/{mes_text}/{dia}_{mes}_{año}_acum024.txt\"\n",
    "\n",
    "    # Formar el enlace completo para el archivo CSV con la fecha actual y siguiente\n",
    "    url_modelo = f\"{enlace_base_mod}{fecha_anterior.strftime('%Y%m%d')}/{fecha.strftime('%Y%m%d')}.lluvia.csv\"\n",
    "\n",
    "    # Verificar si el archivo de lluvia observada y del modelo existe antes de descargarlo\n",
    "    response_obs = requests.get(url_observado)\n",
    "    response_mod = requests.get(url_modelo)\n",
    "\n",
    "    # Verificar si ambos archivos están disponibles\n",
    "    if response_obs.status_code == 200 and response_mod.status_code == 200:\n",
    "        # Decodificar y leer los datos del archivo CSV de lluvia pronosticada\n",
    "        mod_data = response_mod.content.decode('utf-8')\n",
    "        df = pd.read_csv(io.StringIO(mod_data), header=None, names=COLUMN_NAMES)\n",
    "\n",
    "        # Verificar la presencia de valores negativos o cadenas en el archivo de lluvia pronosticada\n",
    "        negative_values = (df[COLUMN_NAMES[1:]] < 0).any(axis=0)\n",
    "        str_values = df[COLUMN_NAMES[1:]].applymap(lambda x: isinstance(x, str)).any(axis=0)\n",
    "\n",
    "        # Si hay valores problemáticos, mostrar un mensaje y no cargar el archivo\n",
    "        if (negative_values.any() or str_values.any()):\n",
    "            print(f\"Valores de lluvia pronosticada para la fecha {fecha} son negativos o del tipo str. No se carga el archivo.\")\n",
    "            missing_data.append(fecha.strftime(\"%Y%m%d\")) # Agregar la fecha del archivo faltante\n",
    "\n",
    "            # Verificar si es necesario cargar datos de lluvia observada de cuatro días atrás\n",
    "            if len(missing_data) < 2:\n",
    "                fecha_sust = fecha_inicio  # Obtener la fecha siguiente\n",
    "                fecha_sust_anterior = fecha_inicio - timedelta(days=1)\n",
    "                datos_pronostico, datos_observados, file_date = cargar_datos(fecha_sust, fecha_sust_anterior, COLUMN_NAMES, enlace_base_obs, enlace_base_mod, meses_espanol)\n",
    "            else:\n",
    "                print(f\"Hay más de dos archivos faltantes\")\n",
    "        else:\n",
    "            # Almacenar datos observados, pronosticados y la fecha en listas correspondientes\n",
    "            datos_observados[fecha] = response_obs.text\n",
    "            datos_pronostico.append(df)\n",
    "            file_date.append(fecha.strftime('%Y%m%d'))\n",
    "    else:\n",
    "        # Si falta algún archivo, mostrar un mensaje y agregar la fecha a la lista de datos faltantes\n",
    "        print(f\"Hay archivos faltantes para la fecha {fecha}\")\n",
    "        missing_data.append(fecha.strftime(\"%Y%m%d\"))\n",
    "\n",
    "        # Verificar si es necesario cargar datos de lluvia observada de cuatro días atrás\n",
    "        if len(missing_data) < 2:\n",
    "            fecha_sust = fecha_inicio  # Obtener la fecha siguiente\n",
    "            fecha_sust_anterior = fecha_inicio - timedelta(days=1)\n",
    "            datos_pronostico, datos_observados, file_date = cargar_datos(fecha_sust, fecha_sust_anterior, COLUMN_NAMES, enlace_base_obs, enlace_base_mod, meses_espanol)\n",
    "        else:\n",
    "            print(f\"Hay más de dos archivos faltantes\")\n",
    "\n",
    "    # Actualizar la fecha anterior para la próxima iteración del ciclo\n",
    "    fecha_anterior = fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bce5a",
   "metadata": {},
   "source": [
    "## Dar formato a datos de pronóstico de Lluvia del WRF 1.5\n",
    "\n",
    "Se realiza una serie de operaciones en el conjunto de datos de pronóstico `datos_pronostico`. En cada iteración, se procesa un DataFrame (`df`) que contiene información de lluvia pronosticada para una fecha específica. \n",
    "\n",
    "En primer lugar, se sustituyen los valores de tipo cadena (`str`) por NaN en las columnas \"1\", \"2\", \"3\" y \"4\". Luego, se convierten a valores numéricos las columnas mencionadas, y se remplazan los valores menores a cero por NaN, asegurando así la coherencia del conjunto de datos.\n",
    "\n",
    "A continuación, se calcula la suma de las columnas \"1\", \"2\", \"3\" y \"4\" para obtener la cantidad total de lluvia pronosticada, y se almacena el resultado en una nueva columna llamada 'Lluvia'. Se seleccionan las columnas 'Estacion' y 'Lluvia' para formar un nuevo DataFrame denominado `data`.\n",
    "\n",
    "Posteriormente, el DataFrame `data` se guarda en dos archivos CSV y TXT con nombres generados basados en la fecha de pronóstico. Estos archivos se almacenan en la carpeta del modelo, específicamente en una subcarpeta llamada 'WRF_Crudo'.\n",
    "\n",
    "Finalmente, se añade el DataFrame `data` a una lista llamada `data_modelo`, que se utiliza para almacenar los DataFrames filtrados correspondientes al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f491da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modelo = []\n",
    "for date, df in zip(file_date,datos_pronostico):\n",
    "\n",
    "    # Sustituir los valores str por NaN en las columnas\n",
    "    df[[\"1\", \"2\", \"3\", \"4\"]] = df[[\"1\", \"2\", \"3\", \"4\"]].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Convertir valores menores a cero en las columnas \"1\", \"2\", \"3\" y \"4\" en NaN\n",
    "    df[[\"1\", \"2\", \"3\", \"4\"]] = df[[\"1\", \"2\", \"3\", \"4\"]].applymap(lambda x: np.nan if x < 0 else x)\n",
    "\n",
    "    # Calcular la suma de las columnas 1, 2, 3 y 4 y almacenar el resultado en la columna 'Lluvia'\n",
    "    df['Lluvia'] = df[[\"1\", \"2\", \"3\", \"4\"]].sum(axis=1, skipna=True)\n",
    "    \n",
    "    data = df[['Estacion', 'Lluvia']]\n",
    "\n",
    "    # Guardar el DataFrame en un archivo CSV con el nombre generado\n",
    "    data.to_csv(os.path.join(carpeta_modelo, 'WRF_Crudo', f\"{date}.lluvia.csv\"), index=False)\n",
    "    data.to_csv(os.path.join(carpeta_modelo, 'WRF_Crudo', f\"{date}.lluvia.txt\"), index=False)\n",
    "    \n",
    "    # Crear una lista de DataFrames filtrados para el modelo\n",
    "    data_modelo.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a20a6c",
   "metadata": {},
   "source": [
    "## Procesamiento y Almacenamiento de Datos Observados\n",
    "En primer lugar, se crea una lista vacía llamada `data_observada`, esta lista se utilizará para almacenar los DataFrames resultantes de los datos observados. Luego, utiliza un bucle para iterar a través de las parejas de `file_date` (fechas en formato texto) y el contenido de archivos previamente guardados en `datos_observados`.\n",
    "\n",
    "Dentro del bucle, el contenido del archivo se divide en líneas utilizando `\"\\n\"` como separador. Se omite la primera línea, que suele ser la cabecera, mediante el uso de `.strip().split(\"\\n\")[1:]`. \n",
    "\n",
    "A continuación, se inicia una lista llamada `estaciones` para almacenar los datos extraídos de las líneas del archivo. El bucle procesa cada línea y divide sus datos por comas utilizando el método `.split(\",\")`. Se verifica si la línea no está vacía y si contiene exactamente 5 campos de datos, lo que indica que tiene la información necesaria. Si esto se cumple, se extraen la identificación de la estación y la cantidad de lluvia registrada durante 24 horas. Luego, estos datos se agregan a la lista `estaciones`\n",
    "\n",
    "Una vez se han procesado todas las líneas del archivo, la lista `estaciones` se convierte en un DataFrame de Pandas llamado `df_estaciones` con las columnas \"Estacion\" y \"Valor\", que representan la estación y la cantidad de lluvia registrada, respectivamente.\n",
    "\n",
    "Finalmente, el DataFrame `df_estaciones` se agrega a la lista `data_observada`, que contiene los archivos de los 3 días anteriores en el formato adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "89f02619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar los DataFrames de datos de lluvia observada luego de ajustar el formato\n",
    "data_observada = []\n",
    "\n",
    "# Iterar sobre las fechas y DataFrames de lluvia observada\n",
    "for date, archivo in zip(file_date, datos_observados.values()):\n",
    "    # Dividir el contenido del DataFrame en líneas usando \"\\n\" como separador\n",
    "    lineas = archivo.strip().split(\"\\n\")[1:]  # Omitir la primera línea que es la cabecera\n",
    "\n",
    "    # Inicializar una lista para almacenar los datos de las estaciones del DataFrame\n",
    "    estaciones = []\n",
    "\n",
    "    # Procesar cada línea para extraer los datos de las estaciones\n",
    "    for linea in lineas:\n",
    "        datos_estacion = linea.split(\",\")  # Dividir la linea por comas\n",
    "\n",
    "        # Asegurarnos de que la línea no esté vacía y tenga todos los campos necesarios\n",
    "        if datos_estacion and len(datos_estacion) == 5:\n",
    "            # Asignar a cada variable la columna adecuada\n",
    "            estacion = datos_estacion[0].split(\"-\")[0] #Dividir por guiones \"-\" y asignar el valor 0\n",
    "            lluvia024 = datos_estacion[3] #Asignar la columna 3\n",
    "\n",
    "            # Solo usar las lineas donde lluvia024 es diferente a 'NA'\n",
    "            if lluvia024 != \"NA\": \n",
    "                estacion = int(estacion) # Convertir el valor a tipo int\n",
    "                lluvia024 = float(lluvia024) # Convertir el valor a tipo float64\n",
    "\n",
    "                # Agregar los datos de la estación y lluvia a la lista estaciones\n",
    "                estaciones.append((estacion, lluvia024))\n",
    "\n",
    "    # Convertir la lista de estaciones en un DataFrame de Pandas para este archivo\n",
    "    df_estaciones = pd.DataFrame(estaciones, columns=[\"Estacion\", \"Lluvia\"])\n",
    "\n",
    "    # Guardar el DataFrame en un archivo CSV con el nombre generado\n",
    "    df_estaciones.to_csv(os.path.join(carpeta_observado, 'Crudo', f\"{date}.lluvia.csv\"), index=False)\n",
    "    df_estaciones.to_csv(os.path.join(carpeta_observado, 'Crudo', f\"{date}.lluvia.txt\"), index=False)\n",
    "\n",
    "    # Agregar el DataFrame con el nuevo formato a la lista de DataFrames\n",
    "    data_observada.append(df_estaciones)## Procesamiento y Almacenamiento de Datos Observados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d395f",
   "metadata": {},
   "source": [
    "## Crear Función para Cargar las Tablas de la Climatología Mensual\n",
    "\n",
    "La función `cargar_clim` está diseñada para facilitar la carga de tablas de climatología mensual de la lluvia desde un archivo Excel. El usuario debe proporcionar la ruta del archivo Excel y una lista de nombres de hojas que desea cargar. La función utiliza la biblioteca Pandas para leer cada hoja especificada, convierte los nombres de las columnas a cadenas de texto y organiza los resultados en un diccionario. Este diccionario tiene como claves los nombres de las hojas y como valores los DataFrames correspondientes, permitiendo un acceso sencillo y organizado a los datos climatológicos cargados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "180249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_clim(ruta_excel, hojas_excel):\n",
    "    \"\"\"\n",
    "    Cargar las tablas de la climatología mensual de la lluvia observada\n",
    "    \n",
    "    Parameters:\n",
    "        ruta_excel (str): Ruta del archivo Excel que contiene las tablas.\n",
    "        hojas_excel (list): Lista de nombres de hojas de Excel a cargar.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario que contiene las tablas cargadas. Las claves son los nombres de las hojas y los valores son DataFrames de Pandas.\n",
    "    \"\"\"\n",
    "    # Crear un diccionario para almacenar las tablas de la climatología mensual (lluvia observada) cargadas desde Excel\n",
    "    clim = {}\n",
    "    \n",
    "    # Iterar sobre la lista de nombres de hojas de Excel a cargar\n",
    "    for hoja in hojas_excel:\n",
    "        # Cargar la tabla desde la hoja de Excel especificada\n",
    "        tabla = pd.read_excel(ruta_excel, sheet_name=hoja)\n",
    "        \n",
    "        # Convertir los nombres de las columnas a cadenas de texto\n",
    "        tabla.columns = tabla.columns.astype(str)\n",
    "        \n",
    "        # Agregar la tabla al diccionario utilizando el nombre de la hoja como clave\n",
    "        clim[hoja] = tabla\n",
    "\n",
    "    return clim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e5486",
   "metadata": {},
   "source": [
    "### Carga de Tablas Climatología Mensual Observada\n",
    "\n",
    "En el código proporcionado, se define la variable `ruta_observado` como la ruta completa de un archivo Excel que contiene la climatología mensual de la lluvia observada. Además, se especifica una lista de nombres de hojas relevantes dentro de ese archivo, que incluyen 'min', 'max' y 'mean'. Luego, se utiliza la función `cargar_clim` con los parámetros `ruta_observado` y `hojas_observado` para cargar las tablas correspondientes desde el archivo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4cfeac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo Excel que contiene la climatología mensual de lluvia observada.\n",
    "ruta_observado = 'C:/Users/arias/OneDrive/Documentos/UCR/TFG/Climatologia/Observado/Lluvia/Climatologia_Mensual_Observada_Lluvia.xlsx'\n",
    "hojas_observado = ['min', 'max', 'mean']\n",
    "\n",
    "#Cargar las tablas de la climatología mensual de la lluvia observada\n",
    "clim_observado = cargar_clim(ruta_observado, hojas_observado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51453fcf",
   "metadata": {},
   "source": [
    "### Carga de Tablas Climatología Mensual del Modelo\n",
    "\n",
    "En el código proporcionado, se define la variable `ruta_modelo` como la ruta completa de un archivo Excel que contiene la climatología mensual de la lluvia pronosticada. Además, se especifica una lista de nombres de hojas relevantes dentro de ese archivo, que incluyen 'min', 'max' y 'mean'. Luego, se utiliza la función `cargar_clim` con los parámetros `ruta_modelo` y `hojas_modelo` para cargar las tablas correspondientes desde el archivo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f8695868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo Excel que contiene la climatología mensual de lluvia observada.\n",
    "ruta_modelo = 'C:/Users/arias/OneDrive/Documentos/UCR/TFG/Climatologia/Modelo/Lluvia/Climatologia_Mensual_Modelo_Lluvia.xlsx'\n",
    "hojas_modelo = ['mean']\n",
    "\n",
    "#Cargar las tablas de la climatología mensual de la lluvia observada\n",
    "clim_modelo = cargar_clim(ruta_modelo, hojas_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9c100",
   "metadata": {},
   "source": [
    "## Control de Calidad con Climatología Mensual Observada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6f784",
   "metadata": {},
   "source": [
    "### Datos de Pronóstico\n",
    "Se inicia verificando que haya datos de lluvia pronosticada (`data_modelo`) antes de continuar con el proceso. Esto evita errores y asegura que el código se ejecute solo cuando haya información para procesar. Luego, el bucle `for` itera a través de las fechas (`file_date`) y sus respectivos DataFrames de pronóstico (`data_modelo`).\n",
    "\n",
    "Se crea o carga la tabla de control de calidad (`tabla_cc_lluvia`) es fundamental. La verificación de la existencia del archivo CSV asociado (`ruta_archivo_cc`) asegura que la tabla se inicie correctamente y, en caso de existir, se carga la versión previa para su actualización.\n",
    "\n",
    "Se procede a eliminar los datos antiguos relacionados con la fecha actual para actualizar los valores. Al verificar si la fecha ya está presente en la tabla, se evita la duplicación de información.\n",
    "\n",
    "Se crea una nueva fila en `tabla_cc_lluvia` para la fecha actual y se ajustan los valores de lluvia pronosticada en función de los límites establecidos por la climatología mensual de lluvia observada. Se itera sobre las columnas de `tabla_cc_lluvia`, cada columna representa una estación meteorológica.\n",
    "\n",
    "Para cada estación y el mes correspondiente, se obtienen los valores mínimo (valor_min) y máximo (valor_max) de lluvia observada de la climatología mensual. Se buscan las filas en el DataFrame pronosticado (file) que coinciden con la estación actual.\n",
    "\n",
    "Se procede con el control de calidad del valor pronosticado (valor_modelo) con los límites establecidos por la climatología observada. Si el valor pronosticado es mayor que el máximo, se ajusta y se registra en la nueva fila (nueva_fila), y se actualiza el valor en file. Si el valor es negativo, también se ajusta. Si el valor está dentro de los límites, se marca con un guion (\"-\"). Si no hay datos pronosticados para la estación en cuestión, se asigna \"x\" en la nueva fila, indicando que no hay datos disponibles para esa estación.\n",
    "\n",
    "Se guarda la tabla de control de calidad ajustada en archivos CSV y TXT. La utilización de nombres de archivo basados en el año de la fecha actual facilita la organización para que cada año se cree una nueva tabla.\n",
    "\n",
    "La parte final del código aborda la situación en la que `data_modelo` está vacío. En este caso, se emite un mensaje informativo que señala la ausencia de datos y sugiere que no se pudo realizar el proceso correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "224e2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si data_modelo es None\n",
    "if data_modelo is not None:\n",
    "    for date, file in zip(file_date, data_modelo):\n",
    "\n",
    "        fecha = datetime.strptime(date, \"%Y%m%d\")\n",
    "        \n",
    "        # Ruta completa del archivo que contendrá la tabla de control de calidad\n",
    "        ruta_archivo_cc = os.path.join(carpeta, f\"tabla_cc_lluvia_{fecha.year}.csv\")\n",
    "\n",
    "        # Si el archivo no existe, se crea la tabla vacía y se descargan y procesan los datos\n",
    "        if not os.path.exists(ruta_archivo_cc):\n",
    "            # Continuar con el procesamiento\n",
    "            tabla_cc_lluvia = pd.DataFrame(columns=['FECHA'] + [str(col) for col in data_modelo[0]['Estacion']])\n",
    "        else:\n",
    "            # Si el archivo existe, cargar la tabla y procesar el día siguiente\n",
    "            tabla_cc_lluvia = pd.read_csv(ruta_archivo_cc)\n",
    "\n",
    "        # Convertir fecha_siguiente_str a np.int64 para hacer la comparación correctamente\n",
    "        fecha_siguiente_int = np.int64(date)\n",
    "\n",
    "        # Verificar si la fecha ya existe en la tabla\n",
    "        if fecha_siguiente_int in tabla_cc_lluvia[\"FECHA\"].values:\n",
    "            # Si la fecha ya existe, obtener el índice de la fila existente\n",
    "            idx_fecha_existente = tabla_cc_lluvia.index[tabla_cc_lluvia[\"FECHA\"] == fecha_siguiente_int][0]\n",
    "\n",
    "            # Eliminar la fila existente a partir del índice\n",
    "            tabla_cc_lluvia = tabla_cc_lluvia.drop(idx_fecha_existente)\n",
    "\n",
    "        # Crear una nueva fila con la fecha siguiente\n",
    "        nueva_fila = {col: \"\" for col in tabla_cc_lluvia.columns}\n",
    "        nueva_fila[\"FECHA\"] = date\n",
    "\n",
    "        for estacion in tabla_cc_lluvia.columns[1:]:\n",
    "            if estacion in clim_observado['min'].columns and estacion in clim_observado['max'].columns:\n",
    "                # Obtener los valores de climatología mensual de lluvia observada para la estación y el mes correspondiente\n",
    "                valor_min = clim_observado['min'].loc[clim_observado['min'][\"mes\"] == fecha.month, estacion].values[0]\n",
    "                valor_max = clim_observado['max'].loc[clim_observado['max'][\"mes\"] == fecha.month, estacion].values[0]\n",
    "\n",
    "                # Verificar si existen filas que coincidan con la estación en file\n",
    "                filas_estacion = file.loc[file[\"Estacion\"].astype(str).str.strip() == estacion.strip()]\n",
    "\n",
    "                # Verificar que la fila para la 'estación' en lluvia pronosticada no esté vacía\n",
    "                if not filas_estacion.empty:\n",
    "                    # Obtener el valor de lluvia pronosticada para la estación y el mes correspondiente\n",
    "                    valor_modelo = filas_estacion[\"Lluvia\"].iloc[0]\n",
    "\n",
    "                    # Control calidad de la lluvia pronosticada con los límites de la climatología mensual de lluvia observada\n",
    "                    if valor_modelo >= valor_max:\n",
    "                        nueva_fila[estacion] = f\"{valor_max}({valor_modelo}>Max)\"\n",
    "                        file.loc[filas_estacion.index, \"Lluvia\"] = valor_max\n",
    "                    elif valor_modelo < 0:\n",
    "                        nueva_fila[estacion] = f\"{valor_min}({valor_modelo}<0)\"\n",
    "                        file.loc[filas_estacion.index, \"Lluvia\"] = valor_min\n",
    "                    else:\n",
    "                        nueva_fila[estacion] = \"-\"  # Si el valor está dentro de los límites, asignar \"-\"\n",
    "                else:\n",
    "                    # Si no hay valor para la estación en file, asignar \"x\"\n",
    "                    nueva_fila[estacion] = \"x\"\n",
    "                    print(f'La estación {estacion} no existe en los datos de pronostico de lluvia del WRF1.5')\n",
    "            else:\n",
    "                nueva_fila[estacion] = \"x\"\n",
    "                print(f'La estación {estacion} no existe en las columnas de la Climatología de Lluvia Mensual Observada')\n",
    "\n",
    "        # Convertir los diccionarios en Pandas DataFrames\n",
    "        nueva_fila = pd.DataFrame.from_dict(nueva_fila, orient='index').T\n",
    "\n",
    "        # Concatenar los DataFrames\n",
    "        tabla_cc_lluvia = pd.concat([tabla_cc_lluvia, nueva_fila], ignore_index=True)\n",
    "\n",
    "        # Guardar la tabla ajustada en un archivo CSV y TXT\n",
    "        tabla_cc_lluvia.to_csv(f\"{carpeta}/tabla_cc_lluvia_{fecha.year}.csv\", index=False)\n",
    "        tabla_cc_lluvia.to_csv(os.path.join(carpeta, f\"tabla_cc_lluvia_{fecha.year}.txt\"), index=False)\n",
    "else:\n",
    "        print(\"No se pudieron obtener los datos correctamente ya que el archivo que contiene los datos de pronostico (data_modelo) está vacio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fcbe0e",
   "metadata": {},
   "source": [
    "### Datos Observados\n",
    "Primero se comprueba si la variable `data_observada` no es `None`. Si tiene datos, procede con el procesamiento. En caso contrario, imprime un mensaje indicando que no se pudieron obtener los datos correctamente.\n",
    "\n",
    "Para cada fecha en `file_date` y su respectivo archivo en `data_observada_cc`: Convierte la fecha a un objeto `datetime`, genera la ruta completa del archivo que contendrá la tabla de control de calidad (`ruta_archivo_cc`), verifica si el archivo ya existe. Si no existe, crea una tabla vacía. Si existe, carga la tabla existente. Convierte la fecha a un número entero para facilitar la comparación con fechas en la tabla.\n",
    "\n",
    "Se verifica si la fecha ya existe en la tabla de Control de Calidad. Si existe, elimina la fila existente. Srea una nueva fila con la fecha y procesa los datos de lluvia pronosticada y observada para cada estación.\n",
    "\n",
    "Par}a el control de calidad de datos de lluvia observada, se compara los valores de lluvia observada con los límites de la climatología mensual de lluvia observada y se actualiza los valores en el archivo original (`file`), marcando aquellos que no cumplen con los límites como `NaN`.\n",
    "\n",
    "Guarda la tabla ajustada en un archivo CSV y TXT. Guarda el archivo original con los datos actualizados en una carpeta específica, utilizando el nombre de la fecha como parte del nombre del archivo.\n",
    "\n",
    "Imprime mensajes de advertencia si una estación no existe en los datos observados de lluvia o en las columnas de la climatología mensual observada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "30bb3114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La estación 84237 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84221 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84233 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 73159 no existe en los datos observados de lluvia\n",
      "La estación 96003 no existe en los datos observados de lluvia\n",
      "La estación 90013 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84293 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 73173 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 69751 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 72193 no existe en los datos observados de lluvia\n",
      "La estación 69725 no existe en los datos observados de lluvia\n",
      "La estación 73137 no existe en los datos observados de lluvia\n",
      "La estación 84169 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84237 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84221 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84233 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 73159 no existe en los datos observados de lluvia\n",
      "La estación 96003 no existe en los datos observados de lluvia\n",
      "La estación 90013 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84293 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 73173 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 69751 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 72193 no existe en los datos observados de lluvia\n",
      "La estación 69725 no existe en los datos observados de lluvia\n",
      "La estación 73137 no existe en los datos observados de lluvia\n",
      "La estación 84169 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84237 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84221 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84233 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 73159 no existe en los datos observados de lluvia\n",
      "La estación 96003 no existe en los datos observados de lluvia\n",
      "La estación 90013 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 84293 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 73173 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 69751 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n",
      "La estación 69725 no existe en los datos observados de lluvia\n",
      "La estación 73137 no existe en los datos observados de lluvia\n",
      "La estación 84169 no existe en las columnas de la Climatología de Lluvia Mensual Observada\n"
     ]
    }
   ],
   "source": [
    "# Verificar si data_observada es None\n",
    "if data_observada is not None:\n",
    "    data_observada_cc = data_observada.copy()\n",
    "    for date, file in zip(file_date, data_observada_cc):\n",
    "\n",
    "        fecha = datetime.strptime(date, \"%Y%m%d\")\n",
    "        \n",
    "        # Ruta completa del archivo que contendrá la tabla de control de calidad\n",
    "        ruta_archivo_cc = os.path.join(carpeta, f\"tabla_cc_lluvia_observada_{fecha.year}.csv\")\n",
    "\n",
    "        # Si el archivo no existe, se crea la tabla vacía y se descargan y procesan los datos\n",
    "        if not os.path.exists(ruta_archivo_cc):\n",
    "            # Continuar con el procesamiento\n",
    "            tabla_cc_lluvia_observada = pd.DataFrame(columns=['FECHA'] + [str(col) for col in data_observada_cc[0]['Estacion']])\n",
    "        else:\n",
    "            # Si el archivo existe, cargar la tabla y procesar el día siguiente\n",
    "            tabla_cc_lluvia_observada = pd.read_csv(ruta_archivo_cc)\n",
    "\n",
    "        # Convertir fecha_siguiente_str a np.int64 para hacer la comparación correctamente\n",
    "        date_siguiente_int = np.int64(date)\n",
    "\n",
    "        # Verificar si la fecha ya existe en la tabla\n",
    "        if date_siguiente_int in tabla_cc_lluvia_observada[\"FECHA\"].values:\n",
    "            # Si la fecha ya existe, obtener el índice de la fila existente\n",
    "            idx_date_existente = tabla_cc_lluvia_observada.index[tabla_cc_lluvia_observada[\"FECHA\"] == date_siguiente_int][0]\n",
    "\n",
    "            # Eliminar la fila existente a partir del índice\n",
    "            tabla_cc_lluvia_observada = tabla_cc_lluvia_observada.drop(idx_date_existente)\n",
    "\n",
    "        # Crear una nueva fila con la fecha siguiente\n",
    "        nueva_fila = {col: \"\" for col in tabla_cc_lluvia_observada.columns}\n",
    "        nueva_fila[\"FECHA\"] = date\n",
    "\n",
    "        for estacion in tabla_cc_lluvia_observada.columns[1:]:\n",
    "            if estacion in clim_observado['min'].columns and estacion in clim_observado['max'].columns:\n",
    "                # Obtener los valores de climatología mensual de lluvia observada para la estación y el mes correspondiente\n",
    "                valor_min = clim_observado['min'].loc[clim_observado['min'][\"mes\"] == fecha.month, estacion].values[0]\n",
    "                valor_max = clim_observado['max'].loc[clim_observado['max'][\"mes\"] == fecha.month, estacion].values[0]\n",
    "\n",
    "                # Verificar si existen filas que coincidan con la estación en file\n",
    "                filas_estacion = file.loc[file[\"Estacion\"].astype(str).str.strip() == estacion.strip()]\n",
    "\n",
    "                # Verificar que la fila para la 'estación' en lluvia pronosticada no esté vacía\n",
    "                if not filas_estacion.empty:\n",
    "                    # Obtener el valor de lluvia pronosticada para la estación y el mes correspondiente\n",
    "                    valor_observado = filas_estacion[\"Lluvia\"].iloc[0]\n",
    "\n",
    "                    # Control calidad de la lluvia pronosticada con los límites de la climatología mensual de lluvia observada\n",
    "                    if valor_observado >= valor_max:\n",
    "                        nueva_fila[estacion] = f\"{valor_max}({valor_observado}>Max)\"\n",
    "                        file.loc[filas_estacion.index, \"Lluvia\"] = np.nan\n",
    "                    elif valor_observado < 0:\n",
    "                        nueva_fila[estacion] = f\"{valor_min}({valor_observado}<0)\"\n",
    "                        file.loc[filas_estacion.index, \"Lluvia\"] = np.nan\n",
    "                    else:\n",
    "                        nueva_fila[estacion] = \"-\"  # Si el valor está dentro de los límites, asignar \"-\"\n",
    "                else:\n",
    "                    # Si no hay valor para la estación en file, asignar \"x\"\n",
    "                    nueva_fila[estacion] = \"x\"\n",
    "                    print(f'La estación {estacion} no existe en los datos observados de lluvia')\n",
    "            else:\n",
    "                nueva_fila[estacion] = \"x\"\n",
    "                print(f'La estación {estacion} no existe en las columnas de la Climatología de Lluvia Mensual Observada')\n",
    "\n",
    "        # Convertir los diccionarios en Pandas DataFrames\n",
    "        nueva_fila = pd.DataFrame.from_dict(nueva_fila, orient='index').T\n",
    "\n",
    "        # Concatenar los DataFrames\n",
    "        tabla_cc_lluvia_observada = pd.concat([tabla_cc_lluvia_observada, nueva_fila], ignore_index=True)\n",
    "\n",
    "        # Guardar la tabla ajustada en un archivo CSV y TXT\n",
    "        tabla_cc_lluvia_observada.to_csv(f\"{carpeta}/tabla_cc_lluvia_observada_{fecha.year}.csv\", index=False)\n",
    "        tabla_cc_lluvia_observada.to_csv(os.path.join(carpeta, f\"tabla_cc_lluvia_observada_{fecha.year}.txt\"), index=False)\n",
    "        \n",
    "        # Guardar el DataFrame en un archivo CSV con el nombre generado\n",
    "        file.to_csv(os.path.join(carpeta_observado, 'Editado', f\"{date}.lluvia.csv\"), index=False)\n",
    "        file.to_csv(os.path.join(carpeta_observado, 'Editado', f\"{date}.lluvia.txt\"), index=False)\n",
    "else:\n",
    "        print(\"No se pudieron obtener los datos correctamente ya que el archivo que contiene los datos de pronostico (data_observada) está vacio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952d617",
   "metadata": {},
   "source": [
    "## Pasos previos al Ajuste de Datos con Climatología Mensual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee07ff",
   "metadata": {},
   "source": [
    "### Crear un MAPEO que permite relacionar las cabeceras de cantón con estaciones especificas\n",
    "\n",
    "* Se define un diccionario llamado `mapeo`. Cada clave del diccionario representa el nombre de un cantón de Costa Rica, y el valor asociado a esa clave es una lista de estaciones que se asocian por ubicación a ese cantón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "43d8b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeo = {\n",
    "    'ALAJUELA': ['84185', '84187'],\n",
    "    'ABANGARES': ['78031'],\n",
    "    'ACOSTA': ['88055'],\n",
    "    'AGUIRRE': ['90015'],\n",
    "    'ALAJUELITA': ['84203'],\n",
    "    'ALFARO_RUIZ': ['69737'],\n",
    "    'ALVARADO': ['73141'],\n",
    "    'ASERRI': ['84215', '84217'],\n",
    "    'ATENAS': ['84225'],\n",
    "    'BAGACES': ['76055'],\n",
    "    'BARVA': ['84243', '84197'],\n",
    "    'BELEN': ['84199'],\n",
    "    'BUENOS_AIRES': ['98087'],\n",
    "    'CANAS': ['76055'],\n",
    "    'CARRILLO': ['74067'],\n",
    "    'CARTAGO': ['73123'],\n",
    "    'CD_QUESADA': ['69743', '69701'],\n",
    "    'CORREDORES': ['100651'],\n",
    "    'COTO_BRUS': ['98107', '98109', '98075'],\n",
    "    'CURRIDABAT': ['84203'],\n",
    "    'DESAMPARADOS': ['84203'],\n",
    "    'DOTA': ['88051'],\n",
    "    'EL_GUARCO': ['73123', '73171'],\n",
    "    'ESPARZA': ['80013'],\n",
    "    'ESCAZU': ['84231', '84193'],\n",
    "    'FLORES': ['84199', '84197'],\n",
    "    'GARABITO': ['86013'],\n",
    "    'GOICOECHEA': ['84139'],\n",
    "    'GOLFITO': ['100643'],\n",
    "    'GRECIA': ['84295'],\n",
    "    'GUACIMO': ['73145'],\n",
    "    'GUAPILES': ['73147'],\n",
    "    'GUATUSO': ['69747', '69749'],\n",
    "    'HEREDIA': ['84193', '84243', '84197'],\n",
    "    'HOJANCHA': ['72185'],\n",
    "    'JIMENEZ': ['73149'],\n",
    "    'LA_CRUZ': ['72191'],\n",
    "    'LA_UNION': ['84181', '73129', '84249'],\n",
    "    'LEON_CORTEZ': ['88051', '88047'],\n",
    "    'LIBERIA': ['74063'],\n",
    "    'LIMON': ['81005'],\n",
    "    'LOS_CHILES': ['69633', '69713'],\n",
    "    'MATINA': ['73159', '83007'],\n",
    "    'MONTES_DE_OCA': ['84139', '84203'],\n",
    "    'MONTES_DE_ORO': ['78033'],\n",
    "    'MORA': ['84209', '84283'],\n",
    "    'MORAVIA': ['84139'],\n",
    "    'NANDAYURE': ['72189'],\n",
    "    'NARANJO': ['84239'],\n",
    "    'NICOYA': ['72165', '72183'],\n",
    "    'OREAMUNO': ['73123', '73129'],\n",
    "    'OROTINA': ['82011', '82019', '82017'],\n",
    "    'OSA': ['100655'],\n",
    "    'PALMARES': ['84239'],\n",
    "    'PARAISO': ['73123'],\n",
    "    'PARRITA': ['88049'],\n",
    "    'PAVAS': ['84193', '84285'],\n",
    "    'PEREZ_ZELEDON': ['98097', '94015'],\n",
    "    'POAS': ['84189', '84187'],\n",
    "    'POCOCI': ['73147', '73169'],\n",
    "    'PTO_VIEJO': ['85025', '85023'],\n",
    "    'PUNTARENAS': ['78027'],\n",
    "    'PURISCAL': ['84209'],\n",
    "    'QUEPOS': ['90015'],\n",
    "    'SAN_CARLOS': ['69743', '69701'],\n",
    "    'SAN_ISIDRO': ['84243'],\n",
    "    'SAN_JOSE': ['84141'],\n",
    "    'SAN_MARCOS': ['88051'],\n",
    "    'SAN_MATEO': ['82011'],\n",
    "    'SAN_PABLO': ['84243', '84193'],\n",
    "    'SAN_RAFAEL': ['84243'],\n",
    "    'SAN_RAMON': ['84239'],\n",
    "    'SANTA_ANA': ['84219'],\n",
    "    'SANTA_BARBARA': ['84197'],\n",
    "    'SANTA_CRUZ': ['74053'],\n",
    "    'SANTO_DOMINGO': ['84193'],\n",
    "    'SARAPIQUI': ['69725'],\n",
    "    'SIQUIRRES': ['73159'],\n",
    "    'SIXAOLA': ['87013'],\n",
    "    'TALAMANCA': ['85021'],\n",
    "    'TARRAZU': ['88051'],\n",
    "    'TIBAS': ['84141'],\n",
    "    'TILARAN': ['76063'],\n",
    "    'TORTUGUERO': ['71023'],\n",
    "    'TURRIALBA': ['73151', '73155', '73167'],\n",
    "    'TURRUBARES': ['84225'],\n",
    "    'UPALA': ['69679', '69647'],\n",
    "    'VALVERDE_VEGA': ['84239'],\n",
    "    'VASQUEZ': ['84207', '84213']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78faf5",
   "metadata": {},
   "source": [
    "### Mapeo Invertido\n",
    "\n",
    "Se construye un diccionario inverso llamado `mapeo_invertido`. Inicialmente, se tiene un diccionario `mapeo` que asocia cantones con estaciones meteorológicas. \n",
    "\n",
    "El código realiza un bucle sobre cada elemento del diccionario `mapeo`, en cada iteración para cada estación asociado a un canton, se verifica si dicho código ya está presente en el diccionario inverso `mapeo_invertido`. Si la estación ya existe, se agrega el cantón actual a la lista existente de cantones asociadas a esa estación. En caso contrario, se crea una nueva entrada en `mapeo_invertido` con la estación como clave y una lista que contiene el cantón actual como único elemento.\n",
    "\n",
    "El resultado final es un diccionario inverso que asocia cada estación con una lista de cantones de Costa Rica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6f85391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeo_invertido = {}\n",
    "\n",
    "for ubicacion, codigos in mapeo.items():\n",
    "    for codigo in codigos:\n",
    "        if codigo in mapeo_invertido:\n",
    "            mapeo_invertido[codigo].append(ubicacion)\n",
    "        else:\n",
    "            mapeo_invertido[codigo] = [ubicacion]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07448983",
   "metadata": {},
   "source": [
    "### Lista de nombres de las cabeceras de cantón\n",
    "\n",
    "* Crear una lista llamada `names_cantones` que contiene los nombres de cada cantón acomodados en el mismo orden que las columnas del diccionario `clim_modelo`. Lo anterior permitirá renombrar las columnas de `clim_modelo` luego para que tengan un formato correcto y homogeneo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ad2637af",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_cantones = ['ALAJUELA', 'ABANGARES', 'ACOSTA', 'AGUIRRE', 'ALAJUELITA','ALFARO_RUIZ', 'ALVARADO', 'ASERRI', 'ATENAS', \n",
    "           'BAGACES', 'BARVA','BELEN', 'BUENOS_AIRES', 'CANAS', 'CARRILLO', 'CARTAGO', 'CD_QUESADA','CORREDORES', \n",
    "           'COTO_BRUS', 'CURRIDABAT', 'DESAMPARADOS', 'DOTA','EL_GUARCO', 'ESPARZA', 'ESCAZU', 'FLORES', 'GARABITO', \n",
    "           'GOICOECHEA','GOLFITO', 'GRECIA', 'GUACIMO', 'GUAPILES', 'GUATUSO', 'HEREDIA','HOJANCHA', 'JIMENEZ', 'LA_CRUZ', \n",
    "           'LA_UNION', 'LEON_CORTEZ', 'LIBERIA','LIMON', 'LOS_CHILES', 'MATINA', 'MONTES_DE_OCA', 'MONTES_DE_ORO','MORA', \n",
    "           'MORAVIA', 'NANDAYURE', 'NARANJO', 'NICOYA', 'OREAMUNO','OROTINA', 'OSA', 'PALMARES', 'PARAISO', 'PARRITA', \n",
    "           'PAVAS','PEREZ_ZELEDON', 'POAS', 'POCOCI', 'PTO_VIEJO', 'PUNTARENAS','PURISCAL', 'QUEPOS', 'SAN_CARLOS', \n",
    "           'SAN_ISIDRO', 'SAN_JOSE','SAN_MARCOS', 'SAN_MATEO', 'SAN_PABLO', 'SAN_RAFAEL', 'SAN_RAMON','SANTA_ANA', \n",
    "           'SANTA_BARBARA', 'SANTA_CRUZ', 'SANTO_DOMINGO','SARAPIQUI', 'SIQUIRRES', 'SIXAOLA', 'TALAMANCA', 'TARRAZU', \n",
    "           'TIBAS','TILARAN', 'TORTUGUERO', 'TURRIALBA', 'TURRUBARES', 'UPALA', 'VALVERDE_VEGA', 'VASQUEZ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb6ecd",
   "metadata": {},
   "source": [
    "###  Integración y Promedio de datos por Estación usando el Mapeo Invertido\n",
    "\n",
    "Inicialmente, extrae la tabla 'mean' y la transforma en un nuevo DataFrame llamado `df`. Posteriormente, elimina la columna 'mes' de este nuevo DataFrame y renombra sus columnas utilizando nombres específicos de cantones.\n",
    "\n",
    "Se crea un DataFrame vacío llamado `Clim_Modelo_Mean` que servirá para almacenar los resultados finales. \n",
    "\n",
    "Se itera sobre las columnas de `mapeo_invertido`, donde cada estación meteorológica se asigna a una lista de cantones. Dependiendo de si la lista de cantones tiene un solo elemento o más, se asigna directamente el valor correspondiente de `df` a la columna de `Clim_Modelo_Mean` o calcula la media de los valores para manejar el caso de múltiples cantones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "dbf402ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la tabla 'mean' de 'clim_modelo' y convertirla en un nuevo DataFrame 'df'\n",
    "df = clim_modelo['mean']\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Eliminar la columna 'mes' del nuevo DataFrame 'df'\n",
    "df = df.drop('mes', axis=1)\n",
    "\n",
    "# Renombrar las columnas del DataFrame 'df' con los nombres de los cantones\n",
    "df.columns = names_cantones\n",
    "\n",
    "# Crear un nuevo DataFrame 'Clim_Modelo_Mean' para almacenar los resultados finales\n",
    "Clim_Modelo_Mean = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre las columnas del diccionario 'mapeo_invertido'\n",
    "for estacion, cantones in mapeo_invertido.items():\n",
    "    # Verificar si hay un solo elemento en la lista de cantones\n",
    "    if len(cantones) == 1:\n",
    "        Clim_Modelo_Mean[estacion] = df[cantones[0]]  # Asignar directamente el valor correspondiente\n",
    "    else:\n",
    "        # Si hay más de un elemento, calcular la media y manejar valores nulos\n",
    "        Clim_Modelo_Mean[estacion] = df[cantones].mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f5085",
   "metadata": {},
   "source": [
    "### Obtener la diferencia entre la climatología del modelo y la observada para cada cantón.\n",
    "\n",
    "Se calculan las diferencias entre las medias de dos conjuntos de datos: `Clim_Modelo_Mean` y `Clim_Observ_Mean`. Los resultados de estas restas se almacenan en un nuevo DataFrame llamado `Tabla_Resta_Clim`. Además, se agrega la columna 'mes' al DataFrame resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ed9fb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la tabla 'mean' de 'clim_observado' y asignarla a 'Clim_Observ_Mean'\n",
    "Clim_Observ_Mean = clim_observado['mean']\n",
    "\n",
    "# Crear un nuevo DataFrame 'Tabla_Resta_Clim' para almacenar los resultados de las restas\n",
    "Tabla_Resta_Clim = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre las columnas del DataFrame 'Clim_Modelo_Mean'\n",
    "for estacion in Clim_Modelo_Mean.columns:\n",
    "    # Calcular la resta entre las medias de 'Clim_Modelo_Mean' y 'Clim_Observ_Mean' para cada estación\n",
    "    resta = Clim_Modelo_Mean[estacion] - Clim_Observ_Mean[estacion]\n",
    "    \n",
    "    # Asignar directamente la columna de restas al DataFrame 'Tabla_Resta_Clim'\n",
    "    Tabla_Resta_Clim[estacion] = resta\n",
    "\n",
    "# Agregar la columna 'mes' al DataFrame 'Tabla_Resta_Clim'\n",
    "Tabla_Resta_Clim['mes'] = clim_observado['mean']['mes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abcc78",
   "metadata": {},
   "source": [
    "## Ajuste de Datos con Climatología Mensual Observada y Modelada\n",
    "\n",
    "Se inicia verificando si la variable `data_modelo` no es nula. En caso afirmativo, se procede a un bucle que itera sobre cada fecha y su respectivo archivo en `data_modelo`. Para cada iteración, se convierte la fecha de formato string a un objeto `datetime`, y se construye la ruta completa del archivo que contendrá la tabla de ajuste, denominado `tabla_ajuste_lluvia`.\n",
    "\n",
    "A continuación, se evalúa si dicho archivo ya existe. En caso de no existir, se inicializa una nueva tabla de ajuste, `tabla_ajuste_lluvia`, con columnas correspondientes a las fechas y estaciones presentes en los datos modelados.\n",
    "\n",
    "Luego, se procede a iterar sobre las estaciones presentes en `tabla_ajuste_lluvia`. Para cada estación, se verifica si esta existe en la tabla `nueva_tabla` (contiene los valores de la resta de \"Climatología Mensual del Modelo menos Climatología Mensual Observada\") y, en caso afirmativo, se obtiene el valor correspondiente.\n",
    "\n",
    "Posteriormente, se buscan las filas en el archivo de lluvia pronosticada (`file`) que coincidan con la estación actual. Si se encuentran filas correspondientes, se recupera el valor de lluvia pronosticada para la estación y el mes actual. Este valor se ajusta restando la diferencia entre la climatología modelada y observada, y se actualiza el valor en `file`.\n",
    "\n",
    "La tabla de ajuste `tabla_ajuste_lluvia` también se actualiza con los valores ajustados. Además, se registran en esta tabla los ajustes realizados para cada estación.\n",
    "\n",
    "Finalmente, se guardan tanto la tabla de ajuste como los archivos ajustados en formatos CSV y TXT. Este proceso se repite para cada fecha y su respectivo archivo en `data_modelo`. En el caso de que `data_modelo` sea nulo, se emite un mensaje indicando que los datos no se obtuvieron correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "7bbece63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si data_modelo es None\n",
    "if data_modelo is not None:\n",
    "    for date, file in zip(file_date, data_modelo):\n",
    "\n",
    "        fecha = datetime.strptime(date, \"%Y%m%d\")\n",
    "        \n",
    "        # Ruta completa del archivo que contendrá la tabla de ajuste\n",
    "        ruta_archivo_ajuste = os.path.join(carpeta, f\"tabla_ajuste_lluvia_{fecha.year}.csv\")\n",
    "\n",
    "        # Si el archivo no existe, se crea la tabla vacía y se descargan y procesan los datos\n",
    "        if not os.path.exists(ruta_archivo_ajuste):\n",
    "            # Continuar con el procesamiento\n",
    "            tabla_ajuste_lluvia = pd.DataFrame(columns=['FECHA'] + [str(col) for col in data_modelo[0]['Estacion']])\n",
    "        else:\n",
    "            # Si el archivo existe, cargar la tabla y procesar el día siguiente\n",
    "            tabla_ajuste_lluvia = pd.read_csv(ruta_archivo_ajuste)\n",
    "        \n",
    "        # Convertir fecha_siguiente_str a np.int64 para hacer la comparación correctamente\n",
    "        fecha_siguiente_int = np.int64(date)\n",
    "\n",
    "        # Verificar si la fecha ya existe en la tabla\n",
    "        if fecha_siguiente_int in tabla_ajuste_lluvia[\"FECHA\"].values:\n",
    "            # Si la fecha ya existe, obtener el índice de la fila existente\n",
    "            idx_fecha_existente = tabla_ajuste_lluvia.index[tabla_ajuste_lluvia[\"FECHA\"] == fecha_siguiente_int][0]\n",
    "\n",
    "            # Eliminar la fila existente a partir del índice\n",
    "            tabla_ajuste_lluvia = tabla_ajuste_lluvia.drop(idx_fecha_existente)\n",
    "\n",
    "        # Crear una nueva fila con la fecha siguiente\n",
    "        nueva_fila = {col: \"\" for col in tabla_ajuste_lluvia.columns}\n",
    "        nueva_fila[\"FECHA\"] = date\n",
    "\n",
    "        # Iterar sobre las columnas de tabla_ajuste_lluvia\n",
    "        for estacion in tabla_ajuste_lluvia.columns[1:]:\n",
    "            # Verificar que la estación exista en Tabla_Resta_Clim\n",
    "            if estacion in Tabla_Resta_Clim.columns:\n",
    "                # Filtrar según el valor de 'mes' la Tabla_Resta_Clim\n",
    "                valor_resta = Tabla_Resta_Clim.loc[Tabla_Resta_Clim[\"mes\"] == fecha.month, estacion].values[0]\n",
    "\n",
    "                # Verificar si existen filas que coincidan con la estación en data_modelo\n",
    "                filas_estacion = file.loc[file[\"Estacion\"].astype(str).str.strip() == estacion.strip()]\n",
    "\n",
    "                # Verificar que la fila para la 'estación' en data_modelo (lluvia pronosticada) no esté vacía\n",
    "                if not filas_estacion.empty:\n",
    "                    # Obtener el valor de lluvia pronosticada para la estación y el mes correspondiente\n",
    "                    valor_modelo = filas_estacion[\"Lluvia\"].iloc[0]\n",
    "\n",
    "                    # Ajustar el valor de lluvia pronosticada restando la diferencia entre la climatología modelada y observada\n",
    "                    nuevo_valor = valor_modelo - valor_resta\n",
    "                    if nuevo_valor < 0:\n",
    "                        # Actualizar el valor en data_modelo con el ajuste realizado\n",
    "                        file.loc[filas_estacion.index, \"Lluvia\"] = 0\n",
    "\n",
    "                        # Añadir el nuevo valor ajustado a la nueva fila de tabla_ajuste_lluvia\n",
    "                        nueva_fila[estacion] = f\"{0}({valor_modelo})\"\n",
    "                    else:\n",
    "                        # Actualizar el valor en data_modelo con el ajuste realizado\n",
    "                        file.loc[filas_estacion.index, \"Lluvia\"] = nuevo_valor\n",
    "\n",
    "                        # Añadir el nuevo valor ajustado a la nueva fila de tabla_ajuste_lluvia\n",
    "                        nueva_fila[estacion] = f\"{nuevo_valor}({valor_modelo})\"\n",
    "\n",
    "                else:\n",
    "                    # Si no hay valor para la estación en data_modelo, asignar \"x\"\n",
    "                    nueva_fila[estacion] = \"x\"\n",
    "            else:\n",
    "                nueva_fila[estacion] = \"-\"\n",
    "\n",
    "        # Convertir la nueva_fila de tabla_ajuste_lluvia en Pandas DataFrames\n",
    "        nueva_fila = pd.DataFrame.from_dict(nueva_fila, orient='index').T\n",
    "\n",
    "        # Concatenar la nueva_fila con tabla_ajuste_lluvia\n",
    "        tabla_ajuste_lluvia = pd.concat([tabla_ajuste_lluvia, nueva_fila], ignore_index=True)\n",
    "\n",
    "        # Guardar la tabla ajustada en un archivo CSV y TXT\n",
    "        tabla_ajuste_lluvia.to_csv(os.path.join(carpeta, f\"tabla_ajuste_lluvia_{fecha.year}.csv\"), index=False)\n",
    "        tabla_ajuste_lluvia.to_csv(os.path.join(carpeta, f\"tabla_ajuste_lluvia_{fecha.year}.txt\"), index=False)\n",
    "        \n",
    "        # Guardar el DataFrame en un archivo CSV con el nombre generado\n",
    "        file.to_csv(os.path.join(carpeta_modelo, 'WRF_Ajust_Clim', f\"{date}.lluvia.csv\"), index=False)\n",
    "        file.to_csv(os.path.join(carpeta_modelo, 'WRF_Ajust_Clim', f\"{date}.lluvia.txt\"), index=False)\n",
    "\n",
    "else:\n",
    "    print(\"No se pudieron obtener los datos correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db479dbf",
   "metadata": {},
   "source": [
    "## Ajuste de datos con el promedio de la resta de los 3 días anteriores\n",
    "\n",
    "### Crear o Abrir Tabla de Promedios de Resta de los 3 días anteriores\n",
    "\n",
    "Se genera una fecha para el dia siguiente (`fecha`), una fecha anterior (hoy) (`fecha_anterior`), y se extrae el año correspondiente (`ano`). Se define el nombre de la tabla que se creará o abrirá para contener el promedio de la diferencia entre pronóstico y observado. Luego, se verifica si la carpeta especificada existe; si no, se crea. Se construye la ruta completa del archivo de la tabla, y si el archivo no existe, se inicializa la tabla vacía con la columna 'Estacion' del primer conjunto de datos en `data_modelo`. En caso de que `data_modelo` sea `None`, se imprime un mensaje de error. Si el archivo ya existe, los datos se cargan desde el archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9800439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la fecha actual y la fecha anterior\n",
    "fecha = datetime.now().date() + timedelta(days=1)\n",
    "fecha_anterior = datetime.now().date()\n",
    "\n",
    "# Obtener el año actual\n",
    "ano = fecha.year\n",
    "\n",
    "# Definir el nombre de la tabla que contendrá el promedio de la diferencia (pronóstico - observado)\n",
    "nombre_tabla = f\"tabla_promedios_lluvia_{ano}\"\n",
    "\n",
    "# Comprobar si la carpeta existe; si no existe, crearla\n",
    "if not os.path.exists(carpeta):\n",
    "    os.makedirs(carpeta)\n",
    "\n",
    "# Construir la ruta completa del archivo que contendrá la tabla\n",
    "ruta_archivo = os.path.join(carpeta, f\"{nombre_tabla}.csv\")\n",
    "\n",
    "# Si el archivo no existe, crear la tabla vacía\n",
    "if not os.path.exists(ruta_archivo):\n",
    "    if data_modelo is not None:\n",
    "        # Inicializar la tabla con la columna 'Estacion' del primer conjunto de datos en 'data_modelo'\n",
    "        tabla_promedios_lluvia = data_modelo[0][[\"Estacion\"]]\n",
    "    else:\n",
    "        # Imprimir un mensaje de error si no se pudieron obtener los datos correctamente\n",
    "        print(\"No se pudieron obtener los datos correctamente.\")\n",
    "else:\n",
    "    # Si el archivo existe, cargar los datos desde el archivo CSV\n",
    "    tabla_promedios_lluvia = pd.read_csv(ruta_archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b41ccf",
   "metadata": {},
   "source": [
    "### Verificar si hay datos del pronóstico ajustados para los 3 dían anteriores\n",
    "\n",
    "Se especifica la ruta de dos carpetas. La primera carpeta, \"carpeta_wrf_ajust,\" contiene datos ajustados del modelo WRF, mientras que la segunda carpeta, \"carpeta_obs_crudo,\" almacena datos observados.\n",
    "\n",
    "La ejecución del código está condicionada a la existencia y validez de la carpeta \"carpeta_wrf_ajust.\" Si la carpeta existe y es un directorio válido, el programa procede a verificar la cantidad de archivos en dicha carpeta. Si hay al menos 8 archivos, se inicia un proceso de carga de datos.\n",
    "\n",
    "Para cada fecha en la lista de fechas de pronóstico (\"file_date\"), el código construye las rutas completas de los archivos de pronóstico y observados en las carpetas correspondientes. Si ambos archivos existen, se leen en pandas DataFrames y se agregan a las listas \"data_modelo\" y \"data_observada\" respectivamente. También, la fecha se agrega a la lista \"dates.\"\n",
    "\n",
    "En caso de que un archivo no se encuentre en las carpetas especificadas, se imprime un mensaje indicando la ausencia del archivo para esa fecha.\n",
    "\n",
    "Si la carpeta \"carpeta_wrf_ajust\" tiene menos de 8 archivos, se imprime un mensaje indicando la insuficiencia de archivos y se informa que no se cargarán datos ajustados del WRF. Si la carpeta no existe o no es un directorio válido, se emiten mensajes informando de esta situación y también se indica que no se cargarán archivos ajustados del WRF.\n",
    "\n",
    "Finalmente, si las variables \"file_date\" o \"data_modelo\" no contienen datos, se imprime un mensaje indicando que una o ambas tablas están vacías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "005fbaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carpeta tiene 8 o más archivos. Cantidad de archivos: 28\n"
     ]
    }
   ],
   "source": [
    "# Especificar las rutas de las carpetas que contiene los datos\n",
    "carpeta_wrf_ajust = f\"{carpeta}/Modelo/WRF_Ajustado/\"\n",
    "carpeta_obs_crudo = f\"{carpeta}/Observado/Crudo/\"\n",
    "\n",
    "if file_date and data_modelo:\n",
    "    # Verificar si la carpeta existe y es un directorio válido\n",
    "    if os.path.exists(carpeta_wrf_ajust) and os.path.isdir(carpeta_wrf_ajust):\n",
    "        # Obtener la lista de archivos en la carpeta\n",
    "        archivos_en_carpeta = os.listdir(carpeta_wrf_ajust)\n",
    "\n",
    "        # Contar la cantidad de archivos en la carpeta\n",
    "        cantidad_archivos = len(archivos_en_carpeta)\n",
    "\n",
    "        # Verificar si hay 8 o más archivos en la carpeta\n",
    "        if cantidad_archivos >= 8:\n",
    "            print(f\"La carpeta tiene 8 o más archivos. Cantidad de archivos: {cantidad_archivos}\")\n",
    "            data_modelo, data_observada, dates = [], [], []\n",
    "\n",
    "            # Iterar sobre las fechas de pronóstico\n",
    "            for date in file_date:\n",
    "                # Crear la ruta completa del archivo de pronóstico en el directorio local\n",
    "                ruta_wrf_ajust = os.path.join(carpeta_wrf_ajust, f\"{date}.lluvia.csv\")\n",
    "                ruta_obs_crudo = os.path.join(carpeta_obs_crudo, f\"{date}.lluvia.csv\")\n",
    "\n",
    "                # Verificar si el archivo existe en la carpetas\n",
    "                if os.path.exists(ruta_wrf_ajust) and os.path.exists(ruta_obs_crudo):\n",
    "                    # Leer el archivo CSV y agregar los datos al conjunto de datos 'data_modelo'\n",
    "                    file_wrf = pd.read_csv(ruta_wrf_ajust)\n",
    "                    data_modelo.append(file_wrf)\n",
    "                    # Leer el archivo CSV y agregar los datos al conjunto de datos 'data_observada'\n",
    "                    file_obs = pd.read_csv(ruta_obs_crudo)\n",
    "                    data_observada.append(file_obs)\n",
    "                    # Agregar las fechas de datos a 'dates'\n",
    "                    dates.append(date)\n",
    "                else:\n",
    "                    # Imprimir un mensaje si el archivo no se encuentra en la carpeta de datos ajustados del WRF\n",
    "                    print(f'El archivo para el {date} no se encuentra en la carpeta de datos del WRF ajustados o observados')\n",
    "        else:\n",
    "            # Imprimir un mensaje si la carpeta tiene menos de 8 archivos\n",
    "            print(f\"La carpeta tiene menos de 8 archivos. Cantidad de archivos: {cantidad_archivos}\")\n",
    "            print(\"No se cargan archivos del WRF ya ajustados\")\n",
    "    else:\n",
    "        # Imprimir un mensaje si la carpeta no existe o no es un directorio válido\n",
    "        print(\"La carpeta no existe o no es un directorio válido.\")\n",
    "        print(\"No se cargan archivos del WRF ya ajustados\")\n",
    "else:\n",
    "    print(\"Alguna de las tablas o ambas estan vacias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62e4ac",
   "metadata": {},
   "source": [
    "### Obtener la resta (pronostico menos observado) de los 3 días anteriores\n",
    "\n",
    "Se crea una lista llamada `Tablas_diferencias` para almacenar las tablas que contendrán las diferencias calculadas. Luego, se recorren las listas `pro` y `obs` en un bucle para calcular las diferencias entre los DataFrames correspondientes y guardar los resultados en archivos CSV.\n",
    "\n",
    "Dentro del bucle, se realiza una combinación \"left\" entre los DataFrames `data_modelo[i]` y `data_observada[i]` basada en la columna \"Estacion\". Esto combina los datos de ambas fuentes en un solo DataFrame llamado `diferencias`.\n",
    "\n",
    "Se calculan las diferencias restando los valores de lluvia de los DataFrames `data_observada` de los valores de `data_modelo`, y se agregan estas diferencias como una nueva columna llamada \"Resta\" en el DataFrame `diferencias`.\n",
    "\n",
    "Luego, se seleccionan las columnas necesarias (\"Estacion\" y \"Resta\") del DataFrame `diferencias` y se guarda este DataFrame en la lista `Tablas_diferencias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "4c7a540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar los resultados (lluvia pronosticada menos lluvia observada)\n",
    "tablas_diferencias = []\n",
    "\n",
    "if data_modelo and data_observada:\n",
    "    # Recorrer las listas de DataFrames (pro y obs) para calcular las diferencias (pro - obs) para cada día\n",
    "    for i in range(len(data_modelo)):\n",
    "\n",
    "        # Realizar una combinación \"left\" entre pro y obs en base a la columna \"Estacion\"\n",
    "        diferencias = data_modelo[i].merge(data_observada[i], on=\"Estacion\", how=\"left\", suffixes=(\"_pro\", \"_obs\"))\n",
    "\n",
    "        # Calcular las diferencias (pro - obs) y guardarlo en la columna 'Resta'\n",
    "        diferencias[\"Resta\"] = diferencias[\"Lluvia_pro\"] - diferencias[\"Lluvia_obs\"]\n",
    "\n",
    "        # Filtrar para seleccionar solo las columnas necesarias\n",
    "        diferencias = diferencias[[\"Estacion\", \"Resta\"]]\n",
    "        \n",
    "        # Eliminar filas con valores NaN en la columna 'Resta'\n",
    "        diferencias = diferencias.dropna(subset=[\"Resta\"])\n",
    "\n",
    "        # Agregar la tabla diferencias a la lista tablas_diferencias\n",
    "        tablas_diferencias.append(diferencias)\n",
    "else:\n",
    "    print(\"Alguna de las tablas (datos_pronostico y data_observada) o ambas estan vacias\")## Pronostico menos Observado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07419002",
   "metadata": {},
   "source": [
    "### Obtener el promedio de la resta de los 3 días anteriores\n",
    "\n",
    "Se empieza por concatenar todos los DataFrames presentes en `Tablas_diferencias` en un solo DataFrame llamado `tabla_concatenada`. Esta operación combina todas las tablas de diferencias en una única tabla, lo que facilita el procesamiento conjunto.\n",
    "\n",
    "Después, la función calcula el promedio de las diferencias para cada estación en la tabla concatenada. Esta información se almacena en el DataFrame `tabla_promedio`. La columna del promedio se renombra con el valor de `text_hoy`, que representa el día actual.\n",
    "\n",
    "Se verifica si la columna con el nombre de `text_hoy` ya existe en el DataFrame `tabla_promedios_lluvia`, si esta columna existe, se elimina para evitar duplicados y garantizar la integridad de los datos.\n",
    "\n",
    "A continuación, se fusionan los DataFrames `tabla_promedios_lluvia` y `tabla_promedio` en base a la columna \"Estacion\", utilizando un método de fusión \"outer\". Esto asegura que se incluyan todas las estaciones presentes en ambos DataFrames en la tabla final, manteniendo la coherencia de los datos.\n",
    "\n",
    "La tabla resultante, que ahora contiene los promedios de las diferencias junto con los datos históricos, se guarda en un archivo CSV en la ubicación especificada por `carpeta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "f1803359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta  # Importamos clases relacionadas con fechas y horas.\n",
    "\n",
    "if tablas_diferencias:\n",
    "    # Concatenar las tres tablas de tablas_diferencias en una sola tabla\n",
    "    tabla_concatenada = pd.concat(tablas_diferencias)\n",
    "\n",
    "    # Calcular el promedio agrupando por Estación\n",
    "    tabla_promedio = tabla_concatenada.groupby(\"Estacion\")[\"Resta\"].mean().reset_index()\n",
    "\n",
    "    # Obtener la fecha actual en formato texto y renombrar la columna 'Resta' de tabla_promedio\n",
    "    text = fecha.strftime(\"%Y%m%d\")\n",
    "    tabla_promedio = tabla_promedio.rename(columns={\"Resta\": f\"{text}\"})\n",
    "\n",
    "    # Verificar si la columna ya existe en tabla_promedios_lluvia\n",
    "    if f\"{text}\" in tabla_promedios_lluvia.columns:\n",
    "        # Si existe la columna existe, eliminarla.\n",
    "        tabla_promedios_lluvia.drop(columns=[f\"{text}\"], inplace=True)\n",
    "\n",
    "    # Fusionar tabla_promedios_lluvia con tabla_promedio\n",
    "    tabla_promedios_lluvia = tabla_promedios_lluvia.merge(tabla_promedio, on=\"Estacion\", how=\"outer\")\n",
    "\n",
    "    # Guardar la tabla_promedios_lluvia en un archivo CSV y TXT\n",
    "    tabla_promedios_lluvia.to_csv(f\"{carpeta}/tabla_promedios_lluvia_{ano}.csv\", index=False)\n",
    "    tabla_promedios_lluvia.to_csv(os.path.join(carpeta, f\"tabla_promedios_lluvia_{ano}.txt\"), index=False)\n",
    "else:\n",
    "    print(\"Tabla diferencias está vacía\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2c0fa",
   "metadata": {},
   "source": [
    "### Cargar pronóstico de mañana\n",
    "\n",
    "Primero, se construye el enlace completo utilizando una URL base, la fecha actual y la fecha siguiente. Luego, se utiliza la biblioteca `requests` para verificar la existencia del archivo en la URL especificada. Si la respuesta del servidor es exitosa (código 200), se procede a procesar el contenido del archivo.\n",
    "\n",
    "El código decodifica el contenido CSV y lo convierte en un DataFrame de Pandas. Se realiza una verificación para detectar valores negativos o de tipo cadena en las columnas relevantes del DataFrame. Si se encuentran tales valores, se imprime un mensaje indicando que el archivo no se cargará. En caso contrario, se efectúan diversas operaciones en el DataFrame para manipular y limpiar los datos.\n",
    "\n",
    "Se sustituyen los valores de tipo cadena por NaN en ciertas columnas, se convierten a NaN los valores numéricos inferiores a cero, y se calcula la suma de las columnas correspondientes, almacenando el resultado en una nueva columna llamada 'Lluvia'. Finalmente, se crea un nuevo DataFrame con las columnas 'Estacion' y 'Lluvia' y se guarda este DataFrame en archivos CSV y TXT en una ubicación específica.\n",
    "\n",
    "Si la verificación inicial de la existencia del archivo en la URL no es exitosa, se imprime un mensaje indicando que hay archivos faltantes para la fecha actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "cc14ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formar el enlace completo para el archivo CSV con la fecha actual y siguiente¿\n",
    "url_modelo_mañana = f\"{enlace_base_mod}{fecha_anterior.strftime('%Y%m%d')}/{fecha.strftime('%Y%m%d')}.lluvia.csv\"\n",
    "\n",
    "# Verificar si el archivo de lluvia observada existe antes de descargarlo\n",
    "response = requests.get(url_modelo_mañana)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    csv_data = response.content.decode('utf-8')\n",
    "    df = pd.read_csv(io.StringIO(csv_data), header=None, names=COLUMN_NAMES)\n",
    "\n",
    "    negative_values = (df[COLUMN_NAMES[1:]] < 0).any(axis=0)\n",
    "    str_values = df[COLUMN_NAMES[1:]].applymap(lambda x: isinstance(x, str)).any(axis=0)\n",
    "\n",
    "    if (negative_values.any() or str_values.any()):\n",
    "        print(f\"Valores de lluvia pronosticada para {fecha} son negativos o del tipo str. No se carga el archivo.\")\n",
    "    else:\n",
    "        # Sustituir los valores str por NaN en las columnas\n",
    "        df[[\"1\", \"2\", \"3\", \"4\"]] = df[[\"1\", \"2\", \"3\", \"4\"]].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Convertir valores menores a cero en las columnas \"1\", \"2\", \"3\" y \"4\" en NaN\n",
    "        df[[\"1\", \"2\", \"3\", \"4\"]] = df[[\"1\", \"2\", \"3\", \"4\"]].applymap(lambda x: np.nan if x < 0 else x)\n",
    "\n",
    "        # Calcular la suma de las columnas 1, 2, 3 y 4 y almacenar el resultado en la columna 'Lluvia'\n",
    "        df['Lluvia'] = df[[\"1\", \"2\", \"3\", \"4\"]].sum(axis=1, skipna=True)\n",
    "\n",
    "        file = df[['Estacion', 'Lluvia']]\n",
    "\n",
    "        # Guardar el DataFrame en un archivo CSV con el nombre generado\n",
    "        file.to_csv(os.path.join(carpeta_modelo, 'WRF_Crudo', f\"{fecha.strftime('%Y%m%d')}.lluvia.csv\"), index=False)\n",
    "        file.to_csv(os.path.join(carpeta_modelo, 'WRF_Crudo', f\"{fecha.strftime('%Y%m%d')}.lluvia.txt\"), index=False)\n",
    "else:\n",
    "    print(f\"Hay archivos faltantes para la fecha {fecha.strftime('%Y%m%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62070ad6",
   "metadata": {},
   "source": [
    "### Restar al pronóstico de mañana el promedio de la resta de los 3 días previos\n",
    "\n",
    "Se realiza un ajuste en los pronósticos de lluvia para el día siguiente, utilizando información de una tabla de promedios. Mediante un condicional se encarga de verificar la existencia de las variables `tabla_promedio` y `file` en el entorno local. Si ambas variables existen y contienen datos, se procede con el ajuste.\n",
    "\n",
    "Primero, se fusiona el pronóstico del día siguiente con la tabla de promedios, relacionando las estaciones meteorológicas. Luego, se realiza una operación de resta, restando el promedio de los últimos tres días a la lluvia pronosticada para el día de mañana. Se asegura de que el resultado no sea menor que 0.\n",
    "\n",
    "Posteriormente, se filtran las columnas necesarias, en este caso, \"Estacion\" y \"Lluvia\". El DataFrame resultante se guarda en archivos CSV y TXT en una ubicación específica dentro de la carpeta del modelo ajustado.\n",
    "\n",
    "También maneja casos donde las tablas o archivos involucrados puedan estar vacíos o no definidos. Se imprimen mensajes de advertencia en tales situaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "c1df74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"tabla_promedio\" in locals() and \"file\" in locals():\n",
    "    if tabla_promedio is not None and file is not None:\n",
    "        if not tabla_promedio.empty and not file.empty:\n",
    "            # Unir el pronóstico de mañana con la tabla del promedio (pro - obs) de los 3 días previos\n",
    "            Pronostico = file.merge(tabla_promedio, on=\"Estacion\", how=\"left\")\n",
    "            \n",
    "            # Restarle al pronóstico de mañana el promedio de los 3 días previos y asegurarse de que el resultado no sea menor que 0\n",
    "            Pronostico[\"Lluvia\"] = Pronostico.apply(lambda row: max(row[\"Lluvia\"] - row[text] if not np.isnan(row[text]) else row[\"Lluvia\"], 0), axis=1)\n",
    "\n",
    "            # Filtrar para seleccionar solo las columnas necesarias\n",
    "            Pronostico = Pronostico[[\"Estacion\", \"Lluvia\"]]\n",
    "\n",
    "            # Guardar el DataFrame del ajuste del pronóstico de mañana en archivos CSV y TXT\n",
    "            Pronostico.to_csv(os.path.join(carpeta_modelo, 'WRF_Ajustado', f\"{fecha.strftime('%Y%m%d')}.lluvia.csv\"), index=False)\n",
    "            Pronostico.to_csv(os.path.join(carpeta_modelo, 'WRF_Ajustado', f\"{fecha.strftime('%Y%m%d')}.lluvia.txt\"), index=False)\n",
    "        else:\n",
    "            print(\"Alguna de las tablas (tabla_promedio y file) o ambas están vacías\")\n",
    "    else:\n",
    "        print(\"Alguna de las tablas (tabla_promedio y file) no está definida\")\n",
    "else:\n",
    "    print(\"Alguna de las tablas (tabla_promedio y file) no existe en el entorno actual.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e7177434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estacion</th>\n",
       "      <th>Lluvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69633</td>\n",
       "      <td>2.634037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69647</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69679</td>\n",
       "      <td>3.904494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69699</td>\n",
       "      <td>8.422333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69701</td>\n",
       "      <td>4.168444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>100641</td>\n",
       "      <td>13.851400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>100649</td>\n",
       "      <td>1.395333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>100651</td>\n",
       "      <td>1.062067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>100653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100655</td>\n",
       "      <td>1.413500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estacion     Lluvia\n",
       "0      69633   2.634037\n",
       "1      69647   0.000000\n",
       "2      69679   3.904494\n",
       "3      69699   8.422333\n",
       "4      69701   4.168444\n",
       "..       ...        ...\n",
       "91    100641  13.851400\n",
       "92    100649   1.395333\n",
       "93    100651   1.062067\n",
       "94    100653   0.000000\n",
       "95    100655   1.413500\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pronostico"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
